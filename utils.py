import os
import tempfile
import requests
import logging
from urllib.parse import urlparse
from pydub import AudioSegment
from google.cloud import storage
import ffmpeg
from openai import OpenAI
from datetime import timedelta, datetime
import re

# âš™ï¸ è¨­å®š logging
logging.basicConfig(level=logging.INFO)

# âœ… åˆå§‹åŒ– OpenAI clientï¼ˆæ–°ç‰ˆ APIï¼‰
client = OpenAI()

VERSION = "v1.0.3"

def download_video(video_url, download_path):
    logging.info("â¬‡ï¸ æ­£åœ¨ä¸‹è¼‰å½±ç‰‡...")
    with open(download_path, "wb") as f:
        response = requests.get(video_url)
        f.write(response.content)
    logging.info("âœ… å½±ç‰‡ä¸‹è¼‰å®Œæˆ")

def convert_to_mp3(input_path, output_path):
    logging.info("ğŸ§ é–‹å§‹è½‰æ›éŸ³è¨Š...")
    (
        ffmpeg
        .input(input_path)
        .output(output_path, ac=1, ar=16000, ab='32k')
        .run(overwrite_output=True, quiet=True)
    )
    logging.info(f"âœ… éŸ³è¨Šè½‰æ›å®Œæˆï¼š {output_path}")

def split_audio(audio_path, max_mb):
    logging.info("ğŸ“€ è¼‰å…¥éŸ³æª”...")
    audio = AudioSegment.from_file(audio_path)
    max_bytes = max_mb * 1024 * 1024

    chunks = []
    start_ms = 0
    while start_ms < len(audio):
        end_ms = len(audio)
        chunk = audio[start_ms:end_ms]

        while len(chunk.raw_data) > max_bytes and end_ms - start_ms > 5000:
            end_ms -= 5000
            chunk = audio[start_ms:end_ms]

        chunks.append(chunk)
        start_ms = end_ms

    logging.info(f"ğŸ§© å°‡éŸ³æª”åˆ†ç‚º {len(chunks)} æ®µï¼Œæ¯æ®µæœ€å¤§ {max_mb} MB")
    return chunks

def upload_to_gcs(bucket_name, destination_blob_name, source_file_path):
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(destination_blob_name)
    blob.upload_from_filename(source_file_path)
    blob.make_public()
    return blob.public_url

def transcribe_audio(file_path, language, prompt):
    logging.info(f"ğŸ§  ä¸Šå‚³è‡³ Whisper åˆ†æä¸­...ï¼š{file_path}")
    with open(file_path, "rb") as f:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=f,
            language=language,
            response_format="srt",
            prompt=prompt if prompt else None
        )
        return transcript, transcript.response.json().get("usage")

def process_video_task(video_url, user_id, task_id, whisper_language, max_segment_mb, webhook_url, prompt):
    logging.info(f"ğŸ“¥ é–‹å§‹è™•ç†å½±ç‰‡ä»»å‹™ {task_id}")
    logging.info(f"ğŸŒ å½±ç‰‡ä¾†æºï¼š{video_url}")
    logging.info(f"ğŸ‘¤ ä½¿ç”¨è€…ï¼š{user_id}")
    logging.info(f"ğŸŒ èªè¨€ï¼š{whisper_language}")
    logging.info(f"ğŸ“¦ Chunk ä¸Šé™ï¼š{max_segment_mb} MB")
    logging.info(f"ğŸ”” Webhookï¼š{webhook_url}")
    logging.info(f"ğŸ“ æç¤ºè©ï¼š{prompt}")
    logging.info(f"ğŸ§ª ç¨‹å¼ç‰ˆæœ¬ï¼š{VERSION}")

    status = "æˆåŠŸ"
    usage_total = {
        "type": "tokens",
        "input_tokens": 0,
        "input_token_details": {"text_tokens": 0, "audio_tokens": 0},
        "output_tokens": 0,
        "total_tokens": 0
    }
    srt_url = ""
    output_srt = ""

    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            logging.info(f"ğŸ“ å»ºç«‹æš«å­˜è³‡æ–™å¤¾ï¼š{tmpdir}")

            input_path = os.path.join(tmpdir, "input_video")
            audio_path = os.path.join(tmpdir, "audio.mp3")

            download_video(video_url, input_path)
            convert_to_mp3(input_path, audio_path)
            chunks = split_audio(audio_path, max_segment_mb)

            bucket_name = "bubblebucket-a1q5lb"
            path_parts = urlparse(video_url).path.lstrip("/").split("/")
            object_path = "/".join(path_parts[1:-1])

            base_time = 0
            for i, chunk in enumerate(chunks):
                chunk_filename = f"chunk_{i}.mp3"
                chunk_path = os.path.join(tmpdir, chunk_filename)
                chunk.export(chunk_path, format="mp3")

                logging.info(f"ğŸ“¤ ç”¢ç”Ÿ {chunk_filename}ï¼ˆ{round(os.path.getsize(chunk_path)/1024/1024, 2)} MBï¼‰")

                gcs_path = f"{object_path}/chunks/{task_id}_{chunk_filename}"
                gcs_url = upload_to_gcs(bucket_name, gcs_path, chunk_path)
                logging.info(f"âœ… ä¸Šå‚³ {chunk_filename} è‡³ GCSï¼š{gcs_url}")

                try:
                    transcript, usage = transcribe_audio(chunk_path, whisper_language, prompt)
                    updated_srt = shift_srt_timestamps(transcript, base_time)
                    output_srt += updated_srt + "\n"
                    base_time += chunk.duration_seconds

                    if usage:
                        usage_total["input_tokens"] += usage.get("input_tokens", 0)
                        usage_total["output_tokens"] += usage.get("output_tokens", 0)
                        usage_total["total_tokens"] += usage.get("total_tokens", 0)
                        audio_tokens = usage.get("audio_tokens", 0)
                        usage_total["input_token_details"]["audio_tokens"] += audio_tokens
                except Exception as e:
                    status = f"å¤±æ•—: Whisper åˆ†æå¤±æ•— - {str(e)}"
                    logging.error(status)

            final_srt_path = os.path.join(tmpdir, "first.srt")
            with open(final_srt_path, "w", encoding="utf-8") as f:
                f.write(output_srt.strip())

            try:
                srt_gcs_path = f"{object_path}/srt/first.srt"
                srt_url = upload_to_gcs(bucket_name, srt_gcs_path, final_srt_path)
                logging.info(f"ğŸ“„ SRT å·²ä¸Šå‚³è‡³ GCSï¼š{srt_url}")
            except Exception as e:
                status = f"å¤±æ•—: ä¸Šå‚³ SRT å¤±æ•— - {str(e)}"
                logging.error(status)
    except Exception as e:
        status = f"å¤±æ•—: ä»»å‹™è™•ç†éŒ¯èª¤ - {str(e)}"
        logging.error(status)

    logging.info("ğŸ“¬ ç™¼é€ Webhook å›å‚³...")
    try:
        response = requests.post(webhook_url, json={
            "ä»»å‹™ç‹€æ…‹": status,
            "user_id": user_id,
            "task_id": task_id,
            "video_url": video_url,
            "whisper_language": whisper_language,
            "srt_url": srt_url,
            "usage": usage_total,
            "version": VERSION
        })
        logging.info(f"âœ… Webhook å·²é€å‡ºï¼Œç‹€æ…‹ç¢¼ {response.status_code}")
    except Exception as e:
        logging.error(f"âŒ Webhook ç™¼é€å¤±æ•—ï¼š{e}")

def shift_srt_timestamps(srt_text, base_seconds):
    def parse_time(s):
        return datetime.strptime(s, "%H:%M:%S,%f")

    def format_time(t):
        return t.strftime("%H:%M:%S,%f")[:-3]

    updated_lines = []
    for line in srt_text.splitlines():
        match = re.match(r"(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})", line)
        if match:
            start, end = match.groups()
            start_dt = parse_time(start) + timedelta(seconds=base_seconds)
            end_dt = parse_time(end) + timedelta(seconds=base_seconds)
            updated_lines.append(f"{format_time(start_dt)} --> {format_time(end_dt)}")
        else:
            updated_lines.append(line)
    return "\n".join(updated_lines)
