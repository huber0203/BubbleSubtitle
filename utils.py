import os
import tempfile
import shutil
import logging
import requests
from datetime import timedelta
from google.cloud import storage
from google.cloud.video import transcoder_v1
from openai import OpenAI
import subprocess
import io
import time

# åˆå§‹åŒ– OpenAI client
client = OpenAI()

# åˆå§‹åŒ– Google Cloud clients
storage_client = storage.Client()
transcoder_client = transcoder_v1.TranscoderServiceClient()

# åˆå§‹åŒ– logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

VERSION = "v1.6.11" # ç‰ˆæœ¬è™Ÿæ›´æ–°
BUCKET_NAME = "bubblebucket-a1q5lb"
CHUNK_FOLDER = "chunks"
SRT_FOLDER = "srt"
TRANSCODER_FOLDER = "transcoder"

# é…ç½®åƒæ•¸
AUDIO_BATCH_SIZE_MB = 24  # éŸ³æª”ç´¯ç©åˆ°é€™å€‹å¤§å°å°±é€ Whisper
AUDIO_BATCH_SIZE_BYTES = AUDIO_BATCH_SIZE_MB * 1024 * 1024

# Google Cloud é…ç½®
PROJECT_ID = "bubble-dropzone-2-pgxrk7"  # æ­£ç¢ºçš„ project ID
LOCATION = "us-central1"  # ç¾åœ‹ä¸­éƒ¨ï¼Œèˆ‡ US multi-region bucket é…åˆ

def get_audio_duration(file_path):
    """ä½¿ç”¨ ffprobe å–å¾—éŸ³æª”çš„ç²¾ç¢ºæ™‚é•· (ç§’)"""
    try:
        cmd = [
            "ffprobe",
            "-v", "error",
            "-show_entries", "format=duration",
            "-of", "default=noprint_wrappers=1:nokey=1",
            file_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        return float(result.stdout.strip())
    except (subprocess.CalledProcessError, ValueError) as e:
        logger.error(f"âŒ ç„¡æ³•å–å¾—éŸ³æª”æ™‚é•· {os.path.basename(file_path)}: {e}")
        return 0.0

def extract_base_path_from_url(video_url):
    """å¾å½±ç‰‡ URL æå–åŸºç¤è·¯å¾‘"""
    try:
        if video_url.startswith("https://storage.googleapis.com/"):
            gcs_path = video_url.replace("https://storage.googleapis.com/", "")
            base_path = "/".join(gcs_path.split("/")[:-1])
            return base_path
        else:
            raise ValueError(f"URL ä¸æ˜¯æœ‰æ•ˆçš„ GCS HTTP URL: {video_url}")
    except Exception as e:
        logger.error(f"âŒ æå–åŸºç¤è·¯å¾‘å¤±æ•—ï¼š{e}")
        return None

def convert_http_url_to_gcs_uri(http_url):
    """å°‡ HTTP URL è½‰æ›ç‚º GCS URI"""
    try:
        if http_url.startswith("https://storage.googleapis.com/"):
            gcs_path = http_url.replace("https://storage.googleapis.com/", "")
            return f"gs://{gcs_path}"
        else:
            raise ValueError(f"URL ä¸æ˜¯æœ‰æ•ˆçš„ GCS HTTP URL: {http_url}")
    except Exception as e:
        logger.error(f"âŒ URL è½‰æ›å¤±æ•—ï¼š{e}")
        return None

def create_transcoder_job(input_uri, output_folder_uri, job_id):
    """å»ºç«‹ Transcoder ä»»å‹™ä¾†è½‰æ›å½±ç‰‡ç‚º MP3"""
    try:
        logger.info(f"ğŸ¬ å»ºç«‹ Transcoder ä»»å‹™ï¼š{job_id}")
        logger.info(f"ğŸ“¥ è¼¸å…¥ï¼š{input_uri}")
        logger.info(f"ğŸ“¤ è¼¸å‡ºç›®éŒ„ï¼š{output_folder_uri}")
        
        audio_stream = transcoder_v1.AudioStream(
            codec="mp3",
            bitrate_bps=128000,
            sample_rate_hertz=44100,
            channel_count=2
        )
        
        mux_stream = transcoder_v1.MuxStream(
            key="audio_only",
            container="mp3",
            elementary_streams=["audio_stream"]
        )
        
        job = transcoder_v1.Job(
            input_uri=input_uri,
            output_uri=output_folder_uri,
            config=transcoder_v1.JobConfig(
                elementary_streams=[
                    transcoder_v1.ElementaryStream(
                        key="audio_stream",
                        audio_stream=audio_stream
                    )
                ],
                mux_streams=[mux_stream]
            )
        )
        
        parent = f"projects/{PROJECT_ID}/locations/{LOCATION}"
        request = transcoder_v1.CreateJobRequest(
            parent=parent,
            job=job
        )
        
        created_job = transcoder_client.create_job(request=request)
        logger.info(f"âœ… Transcoder ä»»å‹™å»ºç«‹æˆåŠŸï¼š{created_job.name}")
        
        return created_job
        
    except Exception as e:
        logger.error(f"âŒ å»ºç«‹ Transcoder ä»»å‹™å¤±æ•—ï¼š{e}")
        return None

def wait_for_transcoder_job(job_name, timeout_minutes=30):
    """ç­‰å¾… Transcoder ä»»å‹™å®Œæˆ"""
    try:
        logger.info(f"â³ ç­‰å¾… Transcoder ä»»å‹™å®Œæˆï¼š{job_name}")
        
        timeout_seconds = timeout_minutes * 60
        start_time = time.time()
        
        while time.time() - start_time < timeout_seconds:
            job = transcoder_client.get_job(name=job_name)
            
            state_names = {1: "PENDING", 2: "RUNNING", 3: "SUCCEEDED", 4: "FAILED"}
            state_name = state_names.get(job.state, f"UNKNOWN({job.state})")
            logger.info(f"ğŸ“Š ä»»å‹™ç‹€æ…‹ï¼š{state_name}")
            
            if job.state == 3:
                logger.info("âœ… Transcoder ä»»å‹™å®Œæˆ")
                return True
            elif job.state == 4:
                logger.error(f"âŒ Transcoder ä»»å‹™å¤±æ•—")
                if hasattr(job, 'error') and job.error:
                    logger.error(f"éŒ¯èª¤è©³æƒ…ï¼š{job.error}")
                return False
            
            time.sleep(30)
        
        logger.error(f"â° Transcoder ä»»å‹™è¶…æ™‚ ({timeout_minutes} åˆ†é˜)")
        return False
        
    except Exception as e:
        logger.error(f"âŒ ç­‰å¾… Transcoder ä»»å‹™å¤±æ•—ï¼š{e}")
        return False

def download_audio_from_gcs(gcs_uri, local_path):
    """å¾ GCS ä¸‹è¼‰éŸ³æª”"""
    try:
        if not gcs_uri.startswith("gs://"):
            raise ValueError(f"Invalid GCS URI: {gcs_uri}")
        
        uri_parts = gcs_uri[5:].split("/", 1)
        bucket_name = uri_parts[0]
        blob_name = uri_parts[1]
        
        logger.info(f"ğŸ“¥ å¾ GCS ä¸‹è¼‰éŸ³æª”ï¼š{gcs_uri}")
        
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(blob_name)
        blob.download_to_filename(local_path)
        
        size_mb = round(os.path.getsize(local_path) / 1024 / 1024, 2)
        logger.info(f"âœ… éŸ³æª”ä¸‹è¼‰å®Œæˆï¼š{size_mb} MB")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ä¸‹è¼‰éŸ³æª”å¤±æ•—ï¼š{e}")
        return False

def split_audio_file(audio_path, chunk_size_mb=24):
    """åˆ†å‰²éŸ³æª”ç‚ºå¤šå€‹å°æª”æ¡ˆ"""
    try:
        logger.info(f"ğŸ”ª åˆ†å‰²éŸ³æª”ï¼š{audio_path}")
        
        total_duration = get_audio_duration(audio_path)
        if total_duration == 0.0:
             raise RuntimeError(f"ç„¡æ³•å–å¾—éŸ³æª”æ™‚é•·ï¼š{audio_path}")

        file_size_mb = os.path.getsize(audio_path) / 1024 / 1024
        
        logger.info(f"ğŸ“Š éŸ³æª”ç¸½æ™‚é•·ï¼š{total_duration:.2f}sï¼Œå¤§å°ï¼š{file_size_mb:.2f}MB")
        
        if file_size_mb <= chunk_size_mb:
            logger.info("ğŸ“¦ éŸ³æª”å¤§å°ç¬¦åˆé™åˆ¶ï¼Œä¸éœ€åˆ†å‰²")
            return [audio_path]
        
        chunk_duration = (total_duration * chunk_size_mb) / file_size_mb
        num_chunks = int(total_duration / chunk_duration) + 1
        
        logger.info(f"ğŸ”ª å°‡åˆ†å‰²ç‚º {num_chunks} æ®µï¼Œæ¯æ®µç´„ {chunk_duration:.2f}s")
        
        chunks = []
        base_path = os.path.splitext(audio_path)[0]
        
        for i in range(num_chunks):
            start_time = i * chunk_duration
            
            if start_time >= total_duration:
                break
                
            chunk_path = f"{base_path}_chunk_{i:03d}.mp3"
            
            cmd = [
                "ffmpeg", "-y",
                "-ss", str(start_time),
                "-i", audio_path,
                "-t", str(chunk_duration),
                "-c", "copy",
                chunk_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                logger.error(f"âŒ åˆ†å‰²å¤±æ•—ï¼š{result.stderr}")
                continue
                
            chunks.append(chunk_path)
            chunk_size = round(os.path.getsize(chunk_path) / 1024 / 1024, 2)
            logger.info(f"âœ… åˆ†å‰²å®Œæˆï¼š{os.path.basename(chunk_path)} ({chunk_size} MB)")
        
        return chunks
        
    except Exception as e:
        logger.error(f"âŒ åˆ†å‰²éŸ³æª”å¤±æ•—ï¼š{e}")
        return []

def upload_to_gcs(file_path, blob_path):
    """ä¸Šå‚³æª”æ¡ˆåˆ° GCS"""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(blob_path)
        
        content_type = "application/x-subrip" if file_path.endswith(".srt") else "audio/mpeg"
        blob.upload_from_filename(file_path, content_type=content_type)
        
        return f"https://storage.googleapis.com/{BUCKET_NAME}/{blob_path}"
    except Exception as e:
        logger.error(f"GCS ä¸Šå‚³å¤±æ•—ï¼š{e}")
        raise

def process_video_task_with_transcoder(video_url, user_id, task_id, whisper_language, max_segment_mb, webhook_url, prompt):
    logger.info(f"ğŸ“¥ é–‹å§‹ä½¿ç”¨ Transcoder è™•ç†å½±ç‰‡ä»»å‹™ {task_id}")
    logger.info(f"ğŸŒ å½±ç‰‡ä¾†æºï¼š{video_url}")
    logger.info(f"ğŸ‘¤ ä½¿ç”¨è€…ï¼š{user_id}")
    logger.info(f"ğŸŒ èªè¨€ï¼š{whisper_language}")
    logger.info(f"ğŸµ éŸ³æª”æ‰¹æ¬¡å¤§å°ï¼š{AUDIO_BATCH_SIZE_MB} MB")
    logger.info(f"ğŸ”” Webhookï¼š{webhook_url}")
    logger.info(f"ğŸ“ æç¤ºè©ï¼š{prompt}")
    logger.info(f"ğŸ§ª ç¨‹å¼ç‰ˆæœ¬ï¼š{VERSION}")

    temp_dir = tempfile.mkdtemp()
    try:
        logger.info("ğŸ” æª¢æŸ¥å½±ç‰‡ URL...")
        headers = {"User-Agent": "Mozilla/5.0"}
        head_resp = requests.head(video_url, allow_redirects=True, headers=headers)
        total_size = int(head_resp.headers.get("Content-Length", 0))
        total_mb = round(total_size / 1024 / 1024, 2)
        logger.info(f"ğŸ“ å½±ç‰‡å¤§å°ï¼š{total_mb} MB")

        input_gcs_uri = convert_http_url_to_gcs_uri(video_url)
        if not input_gcs_uri:
            raise RuntimeError(f"ç„¡æ³•è½‰æ›å½±ç‰‡ URL ç‚º GCS URI: {video_url}")
        
        logger.info(f"ğŸ”„ è½‰æ›å¾Œçš„ GCS URIï¼š{input_gcs_uri}")

        base_path = extract_base_path_from_url(video_url)
        if not base_path:
            raise RuntimeError(f"ç„¡æ³•æå–åŸºç¤è·¯å¾‘: {video_url}")
        
        logger.info(f"ğŸ“ åŸºç¤è·¯å¾‘ï¼š{base_path}")

        job_id = f"audio-extract-{user_id}-{task_id}"
        output_gcs_folder = f"gs://{base_path}/transcoder/"
        
        transcoder_job = create_transcoder_job(input_gcs_uri, output_gcs_folder, job_id)
        if not transcoder_job:
            raise RuntimeError("å»ºç«‹ Transcoder ä»»å‹™å¤±æ•—")

        job_name = transcoder_job.name
        if not wait_for_transcoder_job(job_name):
            raise RuntimeError("Transcoder ä»»å‹™å¤±æ•—æˆ–è¶…æ™‚")

        output_gcs_uri = f"gs://{base_path}/transcoder/audio_only.mp3"
        audio_path = os.path.join(temp_dir, "full_audio.mp3")
        if not download_audio_from_gcs(output_gcs_uri, audio_path):
            raise RuntimeError("ä¸‹è¼‰éŸ³æª”å¤±æ•—")

        audio_chunks = split_audio_file(audio_path, AUDIO_BATCH_SIZE_MB)
        if not audio_chunks:
            raise RuntimeError("åˆ†å‰²éŸ³æª”å¤±æ•—")

        final_srt_parts = []
        total_duration_offset = 0.0
        
        for batch_idx, chunk_path in enumerate(audio_chunks):
            batch_count = batch_idx + 1
            logger.info(f"ğŸš€ è™•ç†éŸ³æª”æ‰¹æ¬¡ {batch_count}/{len(audio_chunks)}")
            
            chunk_name = f"audio_batch_{batch_count:03d}.mp3"
            chunk_blob_path = f"{base_path}/chunks/{chunk_name}"
            chunk_blob_path_clean = chunk_blob_path.replace(f"{BUCKET_NAME}/", "")
            upload_url = upload_to_gcs(chunk_path, chunk_blob_path_clean)
            logger.info(f"âœ… éŸ³æª”æ‰¹æ¬¡ä¸Šå‚³ï¼š{upload_url}")
            
            with open(chunk_path, "rb") as f:
                transcript = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=f,
                    response_format="verbose_json",
                    language=whisper_language,
                    prompt=prompt or None,
                )
            
            srt_entries = []
            for segment in transcript.segments:
                start_time = segment.start + total_duration_offset
                end_time = segment.end + total_duration_offset
                
                start_str = str(timedelta(seconds=start_time))[:-3].replace('.', ',')
                end_str = str(timedelta(seconds=end_time))[:-3].replace('.', ',')
                
                srt_entry = f"{start_str} --> {end_str}\n{segment.text.strip()}"
                srt_entries.append(srt_entry)
            
            final_srt_parts.extend(srt_entries)
            
            # ç²å–æ­¤ç‰‡æ®µçš„ç²¾ç¢ºæ™‚é•·ä¸¦æ›´æ–° offset
            chunk_duration = get_audio_duration(chunk_path)
            total_duration_offset += chunk_duration
            
            logger.info(f"ğŸ“ æ‰¹æ¬¡ {batch_count} è½‰éŒ„å®Œæˆï¼Œ{len(srt_entries)} å€‹ç‰‡æ®µã€‚ç‰‡æ®µæ™‚é•·: {chunk_duration:.2f}sã€‚ç´¯è¨ˆ offset: {total_duration_offset:.2f}s")

        if final_srt_parts:
            srt_path = os.path.join(temp_dir, "final.srt")
            with open(srt_path, "w", encoding="utf-8") as f:
                for i, srt_entry in enumerate(final_srt_parts):
                    f.write(f"{i + 1}\n{srt_entry}\n") # ç¢ºä¿æ¯å€‹æ¢ç›®å¾Œæœ‰ç©ºè¡Œ

            srt_blob_path = f"{base_path}/srt/final.srt"
            srt_blob_path_clean = srt_blob_path.replace(f"{BUCKET_NAME}/", "")
            srt_url = upload_to_gcs(srt_path, srt_blob_path_clean)
            logger.info(f"ğŸ“„ SRT å·²ä¸Šå‚³ï¼š{srt_url}")

            payload = {
                "ä»»å‹™ç‹€æ…‹": "æˆåŠŸ",
                "user_id": user_id,
                "task_id": task_id,
                "video_url": video_url,
                "whisper_language": whisper_language,
                "srt_url": srt_url,
                "å½±ç‰‡åŸå§‹å¤§å°MB": total_mb,
                "éŸ³æª”æ‰¹æ¬¡æ•¸": len(audio_chunks),
                "ç¸½æ™‚é•·ç§’": total_duration_offset,
                "è½‰æ›æ–¹å¼": "Google Transcoder API",
                "ç¨‹å¼ç‰ˆæœ¬": VERSION,
            }

            requests.post(webhook_url, json=payload, timeout=10)
            logger.info("âœ… ä»»å‹™å®Œæˆ")
        else:
            raise Exception("æ²’æœ‰æˆåŠŸè™•ç†ä»»ä½•éŸ³æª”æ‰¹æ¬¡")

    except Exception as e:
        logger.error(f"ğŸ”¥ ä»»å‹™è™•ç†éŒ¯èª¤ - {e}")
        payload = {
            "ä»»å‹™ç‹€æ…‹": f"å¤±æ•—: {str(e)}",
            "user_id": user_id,
            "task_id": task_id,
            "video_url": video_url,
            "whisper_language": whisper_language,
            "srt_url": "",
            "ç¨‹å¼ç‰ˆæœ¬": VERSION,
        }
        try:
            requests.post(webhook_url, json=payload, timeout=10)
        except:
            pass
    finally:
        logger.info(f"ğŸ§¹ æ¸…é™¤æš«å­˜è³‡æ–™å¤¾ï¼š{temp_dir}")
        shutil.rmtree(temp_dir, ignore_errors=True)

def process_video_task(video_url, user_id, task_id, whisper_language, max_segment_mb, webhook_url, prompt):
    """ä¸»è¦è™•ç†å‡½æ•¸ - ä½¿ç”¨ Google Transcoder API"""
    return process_video_task_with_transcoder(video_url, user_id, task_id, whisper_language, max_segment_mb, webhook_url, prompt)
