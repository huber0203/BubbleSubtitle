import os
import tempfile
import requests
import logging
from urllib.parse import urlparse
from pydub import AudioSegment
from google.cloud import storage
import ffmpeg
import openai

# âš™ï¸ è¨­å®š logging
logging.basicConfig(level=logging.INFO)

# âœ… åˆå§‹åŒ– OpenAI clientï¼ˆæ–°ç‰ˆ APIï¼‰
openai.api_key = os.getenv("OPENAI_API_KEY")
client = openai.OpenAI()

def download_video(video_url, download_path):
    logging.info("â¬‡ï¸ æ­£åœ¨ä¸‹è¼‰å½±ç‰‡...")
    with open(download_path, "wb") as f:
        response = requests.get(video_url)
        f.write(response.content)
    logging.info("âœ… å½±ç‰‡ä¸‹è¼‰å®Œæˆ")

def convert_to_mp3(input_path, output_path):
    logging.info("ğŸ§ é–‹å§‹è½‰æ›éŸ³è¨Š...")
    (
        ffmpeg
        .input(input_path)
        .output(output_path, ac=1, ar=16000, ab='32k')
        .run(overwrite_output=True, quiet=True)
    )
    logging.info(f"âœ… éŸ³è¨Šè½‰æ›å®Œæˆï¼š {output_path}")

def split_audio(audio_path, max_mb):
    logging.info("ğŸ“€ è¼‰å…¥éŸ³æª”...")
    audio = AudioSegment.from_file(audio_path)
    max_bytes = max_mb * 1024 * 1024

    chunks = []
    start_ms = 0
    while start_ms < len(audio):
        end_ms = len(audio)
        chunk = audio[start_ms:end_ms]

        while len(chunk.raw_data) > max_bytes and end_ms - start_ms > 5000:
            end_ms -= 5000
            chunk = audio[start_ms:end_ms]

        chunks.append(chunk)
        start_ms = end_ms

    logging.info(f"ğŸ§© å°‡éŸ³æª”åˆ†ç‚º {len(chunks)} æ®µï¼Œæ¯æ®µæœ€å¤§ {max_mb} MB")
    return chunks

def upload_to_gcs(bucket_name, destination_blob_name, source_file_path):
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(destination_blob_name)
    blob.upload_from_filename(source_file_path)
    blob.make_public()
    return blob.public_url

def transcribe_audio(file_path, language, prompt):
    logging.info(f"ğŸ§  ä¸Šå‚³è‡³ Whisper åˆ†æä¸­...ï¼š{file_path}")
    with open(file_path, "rb") as f:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=f,
            language=language,
            response_format="srt",
            prompt=prompt if prompt else None
        )
        return transcript

def process_video_task(video_url, user_id, task_id, whisper_language, max_segment_mb, webhook_url, prompt):
    logging.info(f"ğŸ“¥ é–‹å§‹è™•ç†å½±ç‰‡ä»»å‹™ {task_id}")
    logging.info(f"ğŸŒ å½±ç‰‡ä¾†æºï¼š{video_url}")
    logging.info(f"ğŸ‘¤ ä½¿ç”¨è€…ï¼š{user_id}")
    logging.info(f"ğŸŒ èªè¨€ï¼š{whisper_language}")
    logging.info(f"ğŸ“¦ Chunk ä¸Šé™ï¼š{max_segment_mb} MB")
    logging.info(f"ğŸ”” Webhookï¼š{webhook_url}")
    logging.info(f"ğŸ“ æç¤ºè©ï¼š{prompt}")

    with tempfile.TemporaryDirectory() as tmpdir:
        logging.info(f"ğŸ“ å»ºç«‹æš«å­˜è³‡æ–™å¤¾ï¼š{tmpdir}")

        input_path = os.path.join(tmpdir, "input_video")
        audio_path = os.path.join(tmpdir, "audio.mp3")

        # ä¸‹è¼‰å½±ç‰‡
        download_video(video_url, input_path)

        # è½‰éŸ³è¨Š
        convert_to_mp3(input_path, audio_path)

        # åˆ†æ®µ
        chunks = split_audio(audio_path, max_segment_mb)

        output_srt = ""
        bucket_name = "bubblebucket-a1q5lb"
        object_path = "/".join(urlparse(video_url).path.split("/")[1:-1])

        base_time = 0
        for i, chunk in enumerate(chunks):
            chunk_filename = f"chunk_{i}.mp3"
            chunk_path = os.path.join(tmpdir, chunk_filename)
            chunk.export(chunk_path, format="mp3")

            logging.info(f"ğŸ“¤ ç”¢ç”Ÿ {chunk_filename}ï¼ˆ{round(os.path.getsize(chunk_path)/1024/1024, 2)} MBï¼‰")

            # ä¸Šå‚³ GCS
            gcs_path = f"{object_path}/chunks/{task_id}_{chunk_filename}"
            gcs_url = upload_to_gcs(bucket_name, gcs_path, chunk_path)
            logging.info(f"âœ… ä¸Šå‚³ {chunk_filename} è‡³ GCSï¼š{gcs_url}")

            # Whisper åˆ†æ
            try:
                srt_text = transcribe_audio(chunk_path, whisper_language, prompt)
                # èª¿æ•´æ™‚é–“ç¢¼
                updated_srt = shift_srt_timestamps(srt_text, base_time)
                output_srt += updated_srt + "\n"
                base_time += chunk.duration_seconds
            except Exception as e:
                logging.error(f"âŒ Whisper åˆ†æå¤±æ•—ï¼š{e}")

        # ç™¼é€ Webhook
        logging.info("ğŸ“¬ ç™¼é€ Webhook å›å‚³...")
        try:
            response = requests.post(webhook_url, json={
                "task_id": task_id,
                "srt": output_srt.strip()
            })
            logging.info(f"âœ… Webhook å·²é€å‡ºï¼Œç‹€æ…‹ç¢¼ {response.status_code}")
        except Exception as e:
            logging.error(f"âŒ Webhook ç™¼é€å¤±æ•—ï¼š{e}")

def shift_srt_timestamps(srt_text, base_seconds):
    from datetime import timedelta, datetime
    import re

    def parse_time(s):
        return datetime.strptime(s, "%H:%M:%S,%f")

    def format_time(t):
        return t.strftime("%H:%M:%S,%f")[:-3]

    updated_lines = []
    for line in srt_text.splitlines():
        match = re.match(r"(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})", line)
        if match:
            start, end = match.groups()
            start_dt = parse_time(start) + timedelta(seconds=base_seconds)
            end_dt = parse_time(end) + timedelta(seconds=base_seconds)
            updated_lines.append(f"{format_time(start_dt)} --> {format_time(end_dt)}")
        else:
            updated_lines.append(line)
    return "\n".join(updated_lines)
