import os
import tempfile
import shutil
import logging
import requests
from datetime import timedelta
from google.cloud import storage
from google.cloud.video import transcoder_v1
from openai import OpenAI
import subprocess
import io
import time

# åˆå§‹åŒ– OpenAI client
client = OpenAI()

# åˆå§‹åŒ– Google Cloud clients
storage_client = storage.Client()
transcoder_client = transcoder_v1.TranscoderServiceClient()

# åˆå§‹åŒ– logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

VERSION = "v1.6.6"
BUCKET_NAME = "bubblebucket-a1q5lb"
CHUNK_FOLDER = "chunks"
SRT_FOLDER = "srt"
TRANSCODER_FOLDER = "transcoder"

# é…ç½®åƒæ•¸
AUDIO_BATCH_SIZE_MB = 24  # éŸ³æª”ç´¯ç©åˆ°é€™å€‹å¤§å°å°±é€ Whisper
AUDIO_BATCH_SIZE_BYTES = AUDIO_BATCH_SIZE_MB * 1024 * 1024

# Google Cloud é…ç½®
PROJECT_ID = "bubble-dropzone-2-pgxrk7"  # æ­£ç¢ºçš„ project ID
LOCATION = "us-central1"  # ç¾åœ‹ä¸­éƒ¨ï¼Œèˆ‡ US multi-region bucket é…åˆ

def convert_http_url_to_gcs_uri(http_url):
    """å°‡ HTTP URL è½‰æ›ç‚º GCS URI"""
    try:
        # ç§»é™¤ https://storage.googleapis.com/ å‰ç¶´
        if http_url.startswith("https://storage.googleapis.com/"):
            gcs_path = http_url.replace("https://storage.googleapis.com/", "")
            return f"gs://{gcs_path}"
        else:
            # å¦‚æœä¸æ˜¯ GCS HTTP URLï¼Œæ‹‹å‡ºéŒ¯èª¤
            raise ValueError(f"URL ä¸æ˜¯æœ‰æ•ˆçš„ GCS HTTP URL: {http_url}")
    except Exception as e:
        logger.error(f"âŒ URL è½‰æ›å¤±æ•—ï¼š{e}")
        return None
    """å»ºç«‹ Transcoder ä»»å‹™ä¾†è½‰æ›å½±ç‰‡ç‚º MP3"""
    try:
        logger.info(f"ğŸ¬ å»ºç«‹ Transcoder ä»»å‹™ï¼š{job_id}")
        
        # é…ç½®éŸ³æª”è¼¸å‡º
        audio_stream = transcoder_v1.AudioStream(
            codec="mp3",
            bitrate_bps=128000,  # 128kbps
            sample_rate_hertz=44100,
            channel_count=2
        )
        
        # é…ç½® MuxStream (åªè¦éŸ³æª”)
        mux_stream = transcoder_v1.MuxStream(
            key="audio_only",
            container="mp3",
            elementary_streams=["audio_stream"]
        )
        
        # é…ç½® Job
        job = transcoder_v1.Job(
            input_uri=input_uri,
            output_uri=output_uri,
            config=transcoder_v1.JobConfig(
                elementary_streams=[
                    transcoder_v1.ElementaryStream(
                        key="audio_stream",
                        audio_stream=audio_stream
                    )
                ],
                mux_streams=[mux_stream]
            )
        )
        
        # å»ºç«‹ä»»å‹™è«‹æ±‚
        parent = f"projects/{PROJECT_ID}/locations/{LOCATION}"
        request = transcoder_v1.CreateJobRequest(
            parent=parent,
            job=job
        )
        
        # å»ºç«‹ä»»å‹™
        created_job = transcoder_client.create_job(request=request)
        logger.info(f"âœ… Transcoder ä»»å‹™å»ºç«‹æˆåŠŸï¼š{created_job.name}")
        
        return created_job
        
    except Exception as e:
        logger.error(f"âŒ å»ºç«‹ Transcoder ä»»å‹™å¤±æ•—ï¼š{e}")
        return None

def create_transcoder_job(input_uri, output_uri, job_id):
    """å»ºç«‹ Transcoder ä»»å‹™ä¾†è½‰æ›å½±ç‰‡ç‚º MP3"""
    try:
        logger.info(f"ğŸ¬ å»ºç«‹ Transcoder ä»»å‹™ï¼š{job_id}")
        
        # é…ç½®éŸ³æª”è¼¸å‡º
        audio_stream = transcoder_v1.AudioStream(
            codec="mp3",
            bitrate_bps=128000,  # 128kbps
            sample_rate_hertz=44100,
            channel_count=2
        )
        
        # é…ç½® MuxStream (åªè¦éŸ³æª”)
        mux_stream = transcoder_v1.MuxStream(
            key="audio_only",
            container="mp3",
            elementary_streams=["audio_stream"]
        )
        
        # é…ç½® Job
        job = transcoder_v1.Job(
            input_uri=input_uri,
            output_uri=output_uri,
            config=transcoder_v1.JobConfig(
                elementary_streams=[
                    transcoder_v1.ElementaryStream(
                        key="audio_stream",
                        audio_stream=audio_stream
                    )
                ],
                mux_streams=[mux_stream]
            )
        )
        
        # å»ºç«‹ä»»å‹™è«‹æ±‚
        parent = f"projects/{PROJECT_ID}/locations/{LOCATION}"
        request = transcoder_v1.CreateJobRequest(
            parent=parent,
            job=job
        )
        
        # å»ºç«‹ä»»å‹™
        created_job = transcoder_client.create_job(request=request)
        logger.info(f"âœ… Transcoder ä»»å‹™å»ºç«‹æˆåŠŸï¼š{created_job.name}")
        
        return created_job
        
    except Exception as e:
        logger.error(f"âŒ å»ºç«‹ Transcoder ä»»å‹™å¤±æ•—ï¼š{e}")
        return None

def wait_for_transcoder_job(job_name, timeout_minutes=30):
    """ç­‰å¾… Transcoder ä»»å‹™å®Œæˆ"""
    try:
        logger.info(f"â³ ç­‰å¾… Transcoder ä»»å‹™å®Œæˆï¼š{job_name}")
        
        timeout_seconds = timeout_minutes * 60
        start_time = time.time()
        
        while time.time() - start_time < timeout_seconds:
            job = transcoder_client.get_job(name=job_name)
            
            logger.info(f"ğŸ“Š ä»»å‹™ç‹€æ…‹ï¼š{job.state}")
            
            if job.state == transcoder_v1.Job.State.SUCCEEDED:
                logger.info("âœ… Transcoder ä»»å‹™å®Œæˆ")
                return True
            elif job.state == transcoder_v1.Job.State.FAILED:
                logger.error(f"âŒ Transcoder ä»»å‹™å¤±æ•—ï¼š{job.failure_reason}")
                return False
            
            time.sleep(30)  # æ¯ 30 ç§’æª¢æŸ¥ä¸€æ¬¡
        
        logger.error(f"â° Transcoder ä»»å‹™è¶…æ™‚ ({timeout_minutes} åˆ†é˜)")
        return False
        
    except Exception as e:
        logger.error(f"âŒ ç­‰å¾… Transcoder ä»»å‹™å¤±æ•—ï¼š{e}")
        return False

def download_audio_from_gcs(gcs_uri, local_path):
    """å¾ GCS ä¸‹è¼‰éŸ³æª”"""
    try:
        # è§£æ GCS URI
        if not gcs_uri.startswith("gs://"):
            raise ValueError(f"Invalid GCS URI: {gcs_uri}")
        
        uri_parts = gcs_uri[5:].split("/", 1)
        bucket_name = uri_parts[0]
        blob_name = uri_parts[1]
        
        logger.info(f"ğŸ“¥ å¾ GCS ä¸‹è¼‰éŸ³æª”ï¼š{gcs_uri}")
        
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(blob_name)
        
        blob.download_to_filename(local_path)
        
        size_mb = round(os.path.getsize(local_path) / 1024 / 1024, 2)
        logger.info(f"âœ… éŸ³æª”ä¸‹è¼‰å®Œæˆï¼š{size_mb} MB")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ä¸‹è¼‰éŸ³æª”å¤±æ•—ï¼š{e}")
        return False

def split_audio_file(audio_path, chunk_size_mb=24):
    """åˆ†å‰²éŸ³æª”ç‚ºå¤šå€‹å°æª”æ¡ˆ"""
    try:
        logger.info(f"ğŸ”ª åˆ†å‰²éŸ³æª”ï¼š{audio_path}")
        
        # å–å¾—éŸ³æª”æ™‚é•·
        cmd = ["ffprobe", "-v", "quiet", "-show_entries", "format=duration", 
               "-of", "csv=p=0", audio_path]
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            raise RuntimeError(f"ç„¡æ³•å–å¾—éŸ³æª”æ™‚é•·ï¼š{result.stderr}")
        
        total_duration = float(result.stdout.strip())
        file_size_mb = os.path.getsize(audio_path) / 1024 / 1024
        
        logger.info(f"ğŸ“Š éŸ³æª”ç¸½æ™‚é•·ï¼š{total_duration:.2f}sï¼Œå¤§å°ï¼š{file_size_mb:.2f}MB")
        
        # å¦‚æœæª”æ¡ˆå°æ–¼é™åˆ¶ï¼Œç›´æ¥è¿”å›
        if file_size_mb <= chunk_size_mb:
            logger.info("ğŸ“¦ éŸ³æª”å¤§å°ç¬¦åˆé™åˆ¶ï¼Œä¸éœ€åˆ†å‰²")
            return [audio_path]
        
        # è¨ˆç®—åˆ†å‰²é»
        chunk_duration = (total_duration * chunk_size_mb) / file_size_mb
        num_chunks = int(total_duration / chunk_duration) + 1
        
        logger.info(f"ğŸ”ª å°‡åˆ†å‰²ç‚º {num_chunks} æ®µï¼Œæ¯æ®µç´„ {chunk_duration:.2f}s")
        
        chunks = []
        base_path = os.path.splitext(audio_path)[0]
        
        for i in range(num_chunks):
            start_time = i * chunk_duration
            end_time = min((i + 1) * chunk_duration, total_duration)
            
            if start_time >= total_duration:
                break
                
            chunk_path = f"{base_path}_chunk_{i:03d}.mp3"
            
            cmd = [
                "ffmpeg", "-y",
                "-i", audio_path,
                "-ss", str(start_time),
                "-t", str(end_time - start_time),
                "-c", "copy",
                chunk_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                logger.error(f"âŒ åˆ†å‰²å¤±æ•—ï¼š{result.stderr}")
                continue
                
            chunks.append(chunk_path)
            chunk_size = round(os.path.getsize(chunk_path) / 1024 / 1024, 2)
            logger.info(f"âœ… åˆ†å‰²å®Œæˆï¼š{os.path.basename(chunk_path)} ({chunk_size} MB)")
        
        return chunks
        
    except Exception as e:
        logger.error(f"âŒ åˆ†å‰²éŸ³æª”å¤±æ•—ï¼š{e}")
        return []

def process_audio_batch(accumulated_audio, batch_count, time_offset, whisper_language, prompt, temp_dir, user_id, task_id):
    """è™•ç†ç´¯ç©çš„éŸ³æª”æ‰¹æ¬¡"""
    try:
        # ä¿å­˜ç´¯ç©çš„éŸ³æª”
        batch_audio_path = os.path.join(temp_dir, f"audio_batch_{batch_count:03d}.mp3")
        with open(batch_audio_path, 'wb') as f:
            f.write(accumulated_audio.getvalue())
        
        # ä¸Šå‚³åˆ° GCS
        upload_url = upload_to_gcs(batch_audio_path, f"{user_id}/{task_id}/{CHUNK_FOLDER}/audio_batch_{batch_count:03d}.mp3")
        logger.info(f"âœ… éŸ³æª”æ‰¹æ¬¡ä¸Šå‚³ï¼š{upload_url}")
        
        # é€ Whisper è½‰éŒ„
        with open(batch_audio_path, "rb") as f:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="verbose_json",
                language=whisper_language,
                prompt=prompt or None,
            )
        
        # è™•ç†è½‰éŒ„çµæœ
        srt_entries = []
        batch_duration = 0.0
        
        for segment in transcript.segments:
            start_time = segment.start + time_offset
            end_time = segment.end + time_offset
            
            start_str = str(timedelta(seconds=start_time))[:-3].replace('.', ',')
            end_str = str(timedelta(seconds=end_time))[:-3].replace('.', ',')
            
            srt_entry = f"{start_str} --> {end_str}\n{segment.text.strip()}"
            srt_entries.append(srt_entry)
            
            batch_duration = max(batch_duration, segment.end)
        
        logger.info(f"ğŸ“ æ‰¹æ¬¡ {batch_count} è½‰éŒ„å®Œæˆï¼Œ{len(srt_entries)} å€‹ç‰‡æ®µ")
        return srt_entries, batch_duration
        
    except Exception as e:
        logger.error(f"éŸ³æª”æ‰¹æ¬¡è™•ç†å¤±æ•—ï¼š{e}")
        return [], 0.0

def upload_to_gcs(file_path, blob_path):
    """ä¸Šå‚³æª”æ¡ˆåˆ° GCS"""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(blob_path)
        
        content_type = "application/x-subrip" if file_path.endswith(".srt") else "audio/mpeg"
        blob.upload_from_filename(file_path, content_type=content_type)
        
        return f"https://storage.googleapis.com/{BUCKET_NAME}/{blob_path}"
    except Exception as e:
        logger.error(f"GCS ä¸Šå‚³å¤±æ•—ï¼š{e}")
        raise

def process_video_task_with_transcoder(video_url, user_id, task_id, whisper_language, max_segment_mb, webhook_url, prompt):
    logger.info(f"ğŸ“¥ é–‹å§‹ä½¿ç”¨ Transcoder è™•ç†å½±ç‰‡ä»»å‹™ {task_id}")
    logger.info(f"ğŸŒ å½±ç‰‡ä¾†æºï¼š{video_url}")
    logger.info(f"ğŸ‘¤ ä½¿ç”¨è€…ï¼š{user_id}")
    logger.info(f"ğŸŒ èªè¨€ï¼š{whisper_language}")
    logger.info(f"ğŸµ éŸ³æª”æ‰¹æ¬¡å¤§å°ï¼š{AUDIO_BATCH_SIZE_MB} MB")
    logger.info(f"ğŸ”” Webhookï¼š{webhook_url}")
    logger.info(f"ğŸ“ æç¤ºè©ï¼š{prompt}")
    logger.info(f"ğŸ§ª ç¨‹å¼ç‰ˆæœ¬ï¼š{VERSION}")

    temp_dir = tempfile.mkdtemp()
    try:
        # 1. ç¢ºèªå½±ç‰‡å¯ä»¥è¨ªå•ä¸¦è½‰æ›ç‚º GCS URI
        logger.info("ğŸ” æª¢æŸ¥å½±ç‰‡ URL...")
        headers = {"User-Agent": "Mozilla/5.0"}
        head_resp = requests.head(video_url, allow_redirects=True, headers=headers)
        total_size = int(head_resp.headers.get("Content-Length", 0))
        total_mb = round(total_size / 1024 / 1024, 2)
        logger.info(f"ğŸ“ å½±ç‰‡å¤§å°ï¼š{total_mb} MB")

        # è½‰æ› HTTP URL ç‚º GCS URI
        input_gcs_uri = convert_http_url_to_gcs_uri(video_url)
        if not input_gcs_uri:
            raise RuntimeError(f"ç„¡æ³•è½‰æ›å½±ç‰‡ URL ç‚º GCS URI: {video_url}")
        
        logger.info(f"ğŸ”„ è½‰æ›å¾Œçš„ GCS URIï¼š{input_gcs_uri}")

        # 2. å»ºç«‹ Transcoder ä»»å‹™
        job_id = f"audio-extract-{user_id}-{task_id}"
        output_gcs_uri = f"gs://{BUCKET_NAME}/{user_id}/{task_id}/{TRANSCODER_FOLDER}/audio.mp3"
        
        transcoder_job = create_transcoder_job(input_gcs_uri, output_gcs_uri, job_id)
        if not transcoder_job:
            raise RuntimeError("å»ºç«‹ Transcoder ä»»å‹™å¤±æ•—")

        # 3. ç­‰å¾… Transcoder å®Œæˆ
        job_name = transcoder_job.name
        if not wait_for_transcoder_job(job_name):
            raise RuntimeError("Transcoder ä»»å‹™å¤±æ•—æˆ–è¶…æ™‚")

        # 4. ä¸‹è¼‰è½‰æ›å¾Œçš„éŸ³æª”
        audio_path = os.path.join(temp_dir, "full_audio.mp3")
        if not download_audio_from_gcs(output_gcs_uri, audio_path):
            raise RuntimeError("ä¸‹è¼‰éŸ³æª”å¤±æ•—")

        # 5. åˆ†å‰²éŸ³æª”ï¼ˆå¦‚æœéœ€è¦ï¼‰
        audio_chunks = split_audio_file(audio_path, AUDIO_BATCH_SIZE_MB)
        if not audio_chunks:
            raise RuntimeError("åˆ†å‰²éŸ³æª”å¤±æ•—")

        # 6. è™•ç†éŸ³æª”æ‰¹æ¬¡
        final_srt_parts = []
        total_duration_offset = 0.0
        
        for batch_idx, chunk_path in enumerate(audio_chunks):
            batch_count = batch_idx + 1
            logger.info(f"ğŸš€ è™•ç†éŸ³æª”æ‰¹æ¬¡ {batch_count}/{len(audio_chunks)}")
            
            # 6.1 ä¸Šå‚³éŸ³æª”åˆ° GCS
            chunk_name = f"audio_batch_{batch_count:03d}.mp3"
            upload_url = upload_to_gcs(chunk_path, f"{user_id}/{task_id}/{CHUNK_FOLDER}/{chunk_name}")
            logger.info(f"âœ… éŸ³æª”æ‰¹æ¬¡ä¸Šå‚³ï¼š{upload_url}")
            
            # 6.2 é€ Whisper è½‰éŒ„
            with open(chunk_path, "rb") as f:
                transcript = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=f,
                    response_format="verbose_json",
                    language=whisper_language,
                    prompt=prompt or None,
                )
            
            # 6.3 è™•ç†è½‰éŒ„çµæœ
            srt_entries = []
            batch_duration = 0.0
            
            for segment in transcript.segments:
                start_time = segment.start + total_duration_offset
                end_time = segment.end + total_duration_offset
                
                start_str = str(timedelta(seconds=start_time))[:-3].replace('.', ',')
                end_str = str(timedelta(seconds=end_time))[:-3].replace('.', ',')
                
                srt_entry = f"{start_str} --> {end_str}\n{segment.text.strip()}"
                srt_entries.append(srt_entry)
                
                batch_duration = max(batch_duration, segment.end)
            
            final_srt_parts.extend(srt_entries)
            total_duration_offset += batch_duration
            
            logger.info(f"ğŸ“ æ‰¹æ¬¡ {batch_count} è½‰éŒ„å®Œæˆï¼Œ{len(srt_entries)} å€‹ç‰‡æ®µ")

        # 7. ç”Ÿæˆæœ€çµ‚ SRT
        if final_srt_parts:
            srt_path = os.path.join(temp_dir, "final.srt")
            with open(srt_path, "w", encoding="utf-8") as f:
                for i, srt_entry in enumerate(final_srt_parts):
                    f.write(f"{i + 1}\n{srt_entry}\n")

            srt_url = upload_to_gcs(srt_path, f"{user_id}/{task_id}/{SRT_FOLDER}/final.srt")
            logger.info(f"ğŸ“„ SRT å·²ä¸Šå‚³ï¼š{srt_url}")

            # 8. ç™¼é€æˆåŠŸå›æ‡‰
            payload = {
                "ä»»å‹™ç‹€æ…‹": "æˆåŠŸ",
                "user_id": user_id,
                "task_id": task_id,
                "video_url": video_url,
                "whisper_language": whisper_language,
                "srt_url": srt_url,
                "å½±ç‰‡åŸå§‹å¤§å°MB": total_mb,
                "éŸ³æª”æ‰¹æ¬¡æ•¸": len(audio_chunks),
                "ç¸½æ™‚é•·ç§’": total_duration_offset,
                "è½‰æ›æ–¹å¼": "Google Transcoder API",
                "ç¨‹å¼ç‰ˆæœ¬": VERSION,
            }

            requests.post(webhook_url, json=payload, timeout=10)
            logger.info("âœ… ä»»å‹™å®Œæˆ")
        else:
            raise Exception("æ²’æœ‰æˆåŠŸè™•ç†ä»»ä½•éŸ³æª”æ‰¹æ¬¡")

    except Exception as e:
        logger.error(f"ğŸ”¥ ä»»å‹™è™•ç†éŒ¯èª¤ - {e}")
        payload = {
            "ä»»å‹™ç‹€æ…‹": f"å¤±æ•—: {str(e)}",
            "user_id": user_id,
            "task_id": task_id,
            "video_url": video_url,
            "whisper_language": whisper_language,
            "srt_url": "",
            "ç¨‹å¼ç‰ˆæœ¬": VERSION,
        }
        try:
            requests.post(webhook_url, json=payload, timeout=10)
        except:
            pass
    finally:
        logger.info(f"ğŸ§¹ æ¸…é™¤æš«å­˜è³‡æ–™å¤¾ï¼š{temp_dir}")
        shutil.rmtree(temp_dir, ignore_errors=True)

# ä¸»è¦å…¥å£é»
def process_video_task(video_url, user_id, task_id, whisper_language, max_segment_mb, webhook_url, prompt):
    """ä¸»è¦è™•ç†å‡½æ•¸ - ä½¿ç”¨ Google Transcoder API"""
    return process_video_task_with_transcoder(video_url, user_id, task_id, whisper_language, max_segment_mb, webhook_url, prompt)
