import os
import tempfile
import shutil
import logging
import requests
from datetime import timedelta
from google.cloud import storage
from openai import OpenAI
import subprocess
import io

# åˆå§‹åŒ– OpenAI client
client = OpenAI()

# åˆå§‹åŒ– logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

VERSION = "v1.6.0"
BUCKET_NAME = "bubblebucket-a1q5lb"
CHUNK_FOLDER = "chunks"
SRT_FOLDER = "srt"

# é…ç½®åƒæ•¸
VIDEO_CHUNK_SIZE_MB = 50  # å½±ç‰‡åˆ†æ®µå¤§å°
VIDEO_CHUNK_SIZE_BYTES = VIDEO_CHUNK_SIZE_MB * 1024 * 1024
AUDIO_BATCH_SIZE_MB = 24  # éŸ³æª”ç´¯ç©åˆ°é€™å€‹å¤§å°å°±é€ Whisper
AUDIO_BATCH_SIZE_BYTES = AUDIO_BATCH_SIZE_MB * 1024 * 1024

def process_video_task_streaming(video_url, user_id, task_id, whisper_language, max_segment_mb, webhook_url, prompt):
    logger.info(f"ğŸ“¥ é–‹å§‹ä¸²æµè™•ç†å½±ç‰‡ä»»å‹™ {task_id}")
    logger.info(f"ğŸŒ å½±ç‰‡ä¾†æºï¼š{video_url}")
    logger.info(f"ğŸ‘¤ ä½¿ç”¨è€…ï¼š{user_id}")
    logger.info(f"ğŸŒ èªè¨€ï¼š{whisper_language}")
    logger.info(f"ğŸ“¦ å½±ç‰‡åˆ†æ®µå¤§å°ï¼š{VIDEO_CHUNK_SIZE_MB} MB")
    logger.info(f"ğŸµ éŸ³æª”æ‰¹æ¬¡å¤§å°ï¼š{AUDIO_BATCH_SIZE_MB} MB")
    logger.info(f"ğŸ”” Webhookï¼š{webhook_url}")
    logger.info(f"ğŸ“ æç¤ºè©ï¼š{prompt}")
    logger.info(f"ğŸ§ª ç¨‹å¼ç‰ˆæœ¬ï¼š{VERSION}")

    temp_dir = tempfile.mkdtemp()
    try:
        # 1. å–å¾—å½±ç‰‡ç¸½å¤§å°
        headers = {"User-Agent": "Mozilla/5.0"}
        head_resp = requests.head(video_url, allow_redirects=True, headers=headers)
        total_size = int(head_resp.headers.get("Content-Length", 0))
        total_mb = round(total_size / 1024 / 1024, 2)
        logger.info(f"ğŸ“ å½±ç‰‡å¤§å°ï¼š{total_mb} MB")

        # 2. è¨ˆç®—å½±ç‰‡åˆ†æ®µæ•¸é‡
        num_video_chunks = (total_size + VIDEO_CHUNK_SIZE_BYTES - 1) // VIDEO_CHUNK_SIZE_BYTES
        logger.info(f"ğŸ“¦ é è¨ˆåˆ†å‰²ç‚º {num_video_chunks} å€‹å½±ç‰‡æ®µ")

        # 3. éŸ³æª”ç´¯ç©è®Šæ•¸
        accumulated_audio = io.BytesIO()
        accumulated_size = 0
        audio_batch_count = 0
        total_duration_offset = 0.0  # ç´¯è¨ˆæ™‚é–“åç§»
        final_srt_parts = []

        # 4. é€æ®µè™•ç†å½±ç‰‡
        for chunk_idx in range(num_video_chunks):
            start_byte = chunk_idx * VIDEO_CHUNK_SIZE_BYTES
            end_byte = min(start_byte + VIDEO_CHUNK_SIZE_BYTES - 1, total_size - 1)
            
            logger.info(f"ğŸ“¦ è™•ç†å½±ç‰‡æ®µ {chunk_idx + 1}/{num_video_chunks}")
            
            # 4.1 ä¸‹è¼‰å½±ç‰‡æ®µ
            video_chunk_path = os.path.join(temp_dir, f"video_chunk_{chunk_idx:03d}.mp4")
            if not download_video_chunk(video_url, start_byte, end_byte, video_chunk_path):
                logger.error(f"âŒ å½±ç‰‡æ®µ {chunk_idx} ä¸‹è¼‰å¤±æ•—")
                continue
                
            # 4.2 è½‰æ›ç‚ºéŸ³æª”
            audio_chunk_path = os.path.join(temp_dir, f"audio_chunk_{chunk_idx:03d}.mp3")
            chunk_duration = convert_to_audio(video_chunk_path, audio_chunk_path)
            if chunk_duration is None:
                logger.error(f"âŒ éŸ³æª”è½‰æ›å¤±æ•—ï¼šchunk {chunk_idx}")
                continue
                
            # 4.3 è®€å–éŸ³æª”å…§å®¹
            with open(audio_chunk_path, 'rb') as f:
                audio_data = f.read()
            
            audio_size = len(audio_data)
            logger.info(f"ğŸµ éŸ³æª”æ®µ {chunk_idx}: {round(audio_size/1024/1024, 2)} MB, æ™‚é•·: {chunk_duration:.2f}s")
            
            # 4.4 ç´¯ç©éŸ³æª”
            accumulated_audio.write(audio_data)
            accumulated_size += audio_size
            
            # 4.5 æª¢æŸ¥æ˜¯å¦éœ€è¦é€ Whisper
            is_last_chunk = (chunk_idx == num_video_chunks - 1)
            should_process = (accumulated_size >= AUDIO_BATCH_SIZE_BYTES) or is_last_chunk
            
            if should_process and accumulated_size > 0:
                audio_batch_count += 1
                batch_size_mb = round(accumulated_size / 1024 / 1024, 2)
                logger.info(f"ğŸš€ æº–å‚™é€ Whisper æ‰¹æ¬¡ {audio_batch_count}ï¼Œå¤§å°ï¼š{batch_size_mb} MB")
                
                # 4.6 è™•ç†éŸ³æª”æ‰¹æ¬¡
                srt_part, batch_duration = process_audio_batch(
                    accumulated_audio, 
                    audio_batch_count, 
                    total_duration_offset,
                    whisper_language,
                    prompt,
                    temp_dir,
                    user_id,
                    task_id
                )
                
                if srt_part:
                    final_srt_parts.extend(srt_part)
                    total_duration_offset += batch_duration
                    logger.info(f"âœ… æ‰¹æ¬¡ {audio_batch_count} å®Œæˆï¼Œç´¯è¨ˆæ™‚é•·ï¼š{total_duration_offset:.2f}s")
                
                # 4.7 é‡ç½®ç´¯ç©å™¨
                accumulated_audio.close()
                accumulated_audio = io.BytesIO()
                accumulated_size = 0
            
            # 4.8 æ¸…é™¤æš«å­˜æª”æ¡ˆ
            os.remove(video_chunk_path)
            os.remove(audio_chunk_path)

        # 5. ç”Ÿæˆæœ€çµ‚ SRT
        if final_srt_parts:
            srt_path = os.path.join(temp_dir, "final.srt")
            with open(srt_path, "w", encoding="utf-8") as f:
                for i, srt_entry in enumerate(final_srt_parts):
                    f.write(f"{i + 1}\n{srt_entry}\n")

            srt_url = upload_to_gcs(srt_path, f"{user_id}/{task_id}/{SRT_FOLDER}/final.srt")
            logger.info(f"ğŸ“„ SRT å·²ä¸Šå‚³ï¼š{srt_url}")

            # 6. ç™¼é€æˆåŠŸå›æ‡‰
            payload = {
                "ä»»å‹™ç‹€æ…‹": "æˆåŠŸ",
                "user_id": user_id,
                "task_id": task_id,
                "video_url": video_url,
                "whisper_language": whisper_language,
                "srt_url": srt_url,
                "å½±ç‰‡åŸå§‹å¤§å°MB": total_mb,
                "å½±ç‰‡åˆ†æ®µæ•¸": num_video_chunks,
                "éŸ³æª”æ‰¹æ¬¡æ•¸": audio_batch_count,
                "ç¸½æ™‚é•·ç§’": total_duration_offset,
                "ç¨‹å¼ç‰ˆæœ¬": VERSION,
            }

            requests.post(webhook_url, json=payload, timeout=10)
            logger.info("âœ… ä»»å‹™å®Œæˆ")
        else:
            raise Exception("æ²’æœ‰æˆåŠŸè™•ç†ä»»ä½•éŸ³æª”æ‰¹æ¬¡")

    except Exception as e:
        logger.error(f"ğŸ”¥ ä»»å‹™è™•ç†éŒ¯èª¤ - {e}")
        payload = {
            "ä»»å‹™ç‹€æ…‹": f"å¤±æ•—: {str(e)}",
            "user_id": user_id,
            "task_id": task_id,
            "video_url": video_url,
            "whisper_language": whisper_language,
            "srt_url": "",
            "ç¨‹å¼ç‰ˆæœ¬": VERSION,
        }
        try:
            requests.post(webhook_url, json=payload, timeout=10)
        except:
            pass
    finally:
        logger.info(f"ğŸ§¹ æ¸…é™¤æš«å­˜è³‡æ–™å¤¾ï¼š{temp_dir}")
        shutil.rmtree(temp_dir, ignore_errors=True)

def download_video_chunk(video_url, start_byte, end_byte, output_path, max_retries=3):
    """ä¸‹è¼‰å–®å€‹å½±ç‰‡æ®µ"""
    headers = {"User-Agent": "Mozilla/5.0"}
    
    for attempt in range(max_retries):
        try:
            headers["Range"] = f"bytes={start_byte}-{end_byte}"
            logger.info(f"ğŸ“¥ ä¸‹è¼‰ç¯„åœï¼š{headers['Range']}")
            
            with requests.get(video_url, headers=headers, stream=True) as r:
                r.raise_for_status()
                with open(output_path, "wb") as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        f.write(chunk)
            
            size_mb = round(os.path.getsize(output_path) / 1024 / 1024, 2)
            logger.info(f"âœ… å½±ç‰‡æ®µä¸‹è¼‰å®Œæˆï¼š{size_mb} MB")
            return True
            
        except Exception as e:
            logger.warning(f"âš ï¸ ä¸‹è¼‰å¤±æ•—ï¼Œå˜—è©¦ {attempt + 1}/{max_retries}: {e}")
    
    return False

def convert_to_audio(video_path, audio_path):
    """è½‰æ›å½±ç‰‡ç‚ºéŸ³æª”ï¼Œè¿”å›æ™‚é•·"""
    try:
        # ä½¿ç”¨å®¹éŒ¯æ€§æ›´é«˜çš„è¨­å®š
        cmd = [
            "ffmpeg", "-y", 
            "-fflags", "+discardcorrupt+igndts",
            "-i", video_path,
            "-vn", "-acodec", "libmp3lame",
            "-ar", "44100", "-b:a", "32k",
            "-f", "mp3",
            audio_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0:
            logger.error(f"FFmpeg è½‰æª”å¤±æ•—ï¼š{result.stderr}")
            return None
        
        # å–å¾—éŸ³æª”æ™‚é•·
        cmd = ["ffprobe", "-v", "quiet", "-show_entries", "format=duration", 
               "-of", "csv=p=0", audio_path]
        result = subprocess.run(cmd, capture_output=True, text=True)
        duration = float(result.stdout.strip()) if result.stdout.strip() else 0.0
        
        return duration
        
    except Exception as e:
        logger.error(f"éŸ³æª”è½‰æ›éŒ¯èª¤ï¼š{e}")
        return None

def process_audio_batch(accumulated_audio, batch_count, time_offset, whisper_language, prompt, temp_dir, user_id, task_id):
    """è™•ç†ç´¯ç©çš„éŸ³æª”æ‰¹æ¬¡"""
    try:
        # ä¿å­˜ç´¯ç©çš„éŸ³æª”
        batch_audio_path = os.path.join(temp_dir, f"audio_batch_{batch_count:03d}.mp3")
        with open(batch_audio_path, 'wb') as f:
            f.write(accumulated_audio.getvalue())
        
        # ä¸Šå‚³åˆ° GCS
        upload_url = upload_to_gcs(batch_audio_path, f"{user_id}/{task_id}/{CHUNK_FOLDER}/audio_batch_{batch_count:03d}.mp3")
        logger.info(f"âœ… éŸ³æª”æ‰¹æ¬¡ä¸Šå‚³ï¼š{upload_url}")
        
        # é€ Whisper è½‰éŒ„
        with open(batch_audio_path, "rb") as f:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="verbose_json",
                language=whisper_language,
                prompt=prompt or None,
            )
        
        # è™•ç†è½‰éŒ„çµæœ
        srt_entries = []
        batch_duration = 0.0
        
        for segment in transcript.segments:
            start_time = segment.start + time_offset
            end_time = segment.end + time_offset
            
            start_str = str(timedelta(seconds=start_time))[:-3].replace('.', ',')
            end_str = str(timedelta(seconds=end_time))[:-3].replace('.', ',')
            
            srt_entry = f"{start_str} --> {end_str}\n{segment.text.strip()}"
            srt_entries.append(srt_entry)
            
            batch_duration = max(batch_duration, segment.end)
        
        logger.info(f"ğŸ“ æ‰¹æ¬¡ {batch_count} è½‰éŒ„å®Œæˆï¼Œ{len(srt_entries)} å€‹ç‰‡æ®µ")
        return srt_entries, batch_duration
        
    except Exception as e:
        logger.error(f"éŸ³æª”æ‰¹æ¬¡è™•ç†å¤±æ•—ï¼š{e}")
        return [], 0.0

def upload_to_gcs(file_path, blob_path):
    """ä¸Šå‚³æª”æ¡ˆåˆ° GCS"""
    try:
        client = storage.Client()
        bucket = client.bucket(BUCKET_NAME)
        blob = bucket.blob(blob_path)
        
        content_type = "application/x-subrip" if file_path.endswith(".srt") else "audio/mpeg"
        blob.upload_from_filename(file_path, content_type=content_type)
        
        return f"https://storage.googleapis.com/{BUCKET_NAME}/{blob_path}"
    except Exception as e:
        logger.error(f"GCS ä¸Šå‚³å¤±æ•—ï¼š{e}")
        raise

# ä¸»è¦å…¥å£é»
def process_video_task(video_url, user_id, task_id, whisper_language, max_segment_mb, webhook_url, prompt):
    """ä¸»è¦è™•ç†å‡½æ•¸"""
    return process_video_task_streaming(video_url, user_id, task_id, whisper_language, max_segment_mb, webhook_url, prompt)
